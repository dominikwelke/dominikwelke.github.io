<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Dominik Welke</title><link>http://dominikwelke.github.io/</link><description>Very static personal website.</description><atom:link href="http://dominikwelke.github.io/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2024 &lt;a href="mailto:dominik.welke@ae.mpg.de"&gt;CC-BY&lt;/a&gt; </copyright><lastBuildDate>Fri, 09 Feb 2024 11:36:33 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>New position in Leeds </title><link>http://dominikwelke.github.io/news/2023-11-moving-to-leeds/</link><dc:creator>CC-BY</dc:creator><description>&lt;p&gt;Today I started a new position in the EEGManyLabs core team with Yuri Pavlov, Faisal Mushtaq and Jasper van den Bosch.
I'll be based at the Immersive Cognition Lab at the University of Leeds.&lt;/p&gt;
&lt;p&gt;Looking forward to more focussed Open Science work, Big EEG Data, and the foggy Yorkshire moors!&lt;/p&gt;</description><category>changes</category><category>open-science</category><guid>http://dominikwelke.github.io/news/2023-11-moving-to-leeds/</guid><pubDate>Wed, 01 Nov 2023 11:11:11 GMT</pubDate></item><item><title>New contribution: Eye Tracking support for MNE Python </title><link>http://dominikwelke.github.io/news/2023-03-mne-eyetracking/</link><dc:creator>CC-BY</dc:creator><description>&lt;p&gt;Last year I got a scholarship to participate in the MNE-Python 2022 Code Sprint.
Besides some fixes and work in the documentation my main goal was to enable MNE to read and support Eye Tracking data.&lt;/p&gt;
&lt;p&gt;We now merged a first big PR (thanks to &lt;a class="reference external" href="https://github.com/scott-huberty"&gt;Scott Huberty&lt;/a&gt; for joining me and pushing us forward!):&lt;/p&gt;
&lt;p&gt;MNE now has a dedicated class for eye tracking data and can import SR Research's proprietary ASCII files (or work with data in numpy arrays).
Check out the first tutorials &lt;a class="reference external" href="https://mne.tools/stable/auto_tutorials/io/70_reading_eyetracking_data.html"&gt;here&lt;/a&gt;  and &lt;a class="reference external" href="https://mne.tools/stable/auto_tutorials/preprocessing/90_eyetracking_data.html"&gt;here&lt;/a&gt; ;)&lt;/p&gt;</description><category>coding</category><category>open-science</category><guid>http://dominikwelke.github.io/news/2023-03-mne-eyetracking/</guid><pubDate>Tue, 28 Mar 2023 07:12:26 GMT</pubDate></item><item><title>Credibility in Neuroscience award for #EEGManyLabs</title><link>http://dominikwelke.github.io/news/2023-03-eegmanylabs-award/</link><dc:creator>CC-BY</dc:creator><description>&lt;p&gt;&lt;a class="reference external" href="https://osf.io/yb3pq/"&gt;#EEGManyLabs&lt;/a&gt; has been awarded the &lt;em&gt;Team Credibility Prize&lt;/em&gt; of the British Neuroscience Association.
More info on the &lt;a class="reference external" href="https://www.bna.org.uk/mediacentre/news/credibility-prize-2023/"&gt;award website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I contributed to the white paper and am very happy to see this recognition.
Congrats to Faisal Mushtaq and Yuri Pavlov, who started and lead this enormeous replication project!&lt;/p&gt;</description><category>honours</category><guid>http://dominikwelke.github.io/news/2023-03-eegmanylabs-award/</guid><pubDate>Fri, 03 Mar 2023 19:43:34 GMT</pubDate></item><item><title>Participation in MNE-Python's New Developers Code Sprint</title><link>http://dominikwelke.github.io/news/2022-06-mne-code-sprint/</link><dc:creator>CC-BY</dc:creator><description>&lt;p&gt;I was selected to participate in MNE-Python's 2022 New Developers Code Sprint :)&lt;/p&gt;
&lt;p&gt;Besides some other ideas, my main goal will be Eye Tracking support for MNE.
I had contributed before, but am looking forward to a week of learning and coding with the core devs!&lt;/p&gt;</description><category>coding</category><category>open-science</category><guid>http://dominikwelke.github.io/news/2022-06-mne-code-sprint/</guid><pubDate>Wed, 22 Jun 2022 06:42:11 GMT</pubDate></item><item><title>Blitz Talk @ CNS 2022 in San Franscisco</title><link>http://dominikwelke.github.io/news/2022-05-cns-blitz-talk/</link><dc:creator>CC-BY</dc:creator><description>&lt;p&gt;I'm very happy that my submission to this year's meeting of the Cognitive Neuroscience Society was selected for a Blitz presentation!
I sprinted through the findings of my recent publication "Naturalistic viewing conditions can increase task engagement and aesthetic preference but have only minimal impact on EEG quality".&lt;/p&gt;
&lt;p&gt;Slides &lt;a class="reference external" href="https://osf.io/u6f3b"&gt;here&lt;/a&gt; on OSF :)&lt;/p&gt;</description><category>conference</category><category>talk</category><guid>http://dominikwelke.github.io/news/2022-05-cns-blitz-talk/</guid><pubDate>Mon, 23 May 2022 15:32:42 GMT</pubDate></item><item><title>New contribution: Frequency-tagging (SSVEP/ASSR) tutorial for MNE Python </title><link>http://dominikwelke.github.io/news/2021-03-mne-frequencytagging/</link><dc:creator>CC-BY</dc:creator><description>&lt;p&gt;My new tutorial on how to work with frequency-tagged data in MNE-Python has just been merged!
Check it out &lt;a class="reference external" href="https://mne.tools/stable/auto_tutorials/time-freq/50_ssvep.html"&gt;here&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;This is a small spin-off from my current methods-paper on the effect of experimental conditions in EEG studies.
Here we used an auditory (ASSR) stimulus as a proxy measure for EEG recording quality.
Stay tuned for the preprint.&lt;/p&gt;
&lt;p&gt;Thanks to &lt;a class="reference external" href="https://github.com/kalenkovich"&gt;Evgenii Kalenkovich&lt;/a&gt; for working together on the tutorial :)&lt;/p&gt;</description><category>coding</category><category>open-science</category><guid>http://dominikwelke.github.io/news/2021-03-mne-frequencytagging/</guid><pubDate>Fri, 05 Mar 2021 10:16:26 GMT</pubDate></item><item><title>Vice News short about Brain on Screen</title><link>http://dominikwelke.github.io/news/2019-05-vice-news-brain-on-screen/</link><dc:creator>CC-BY</dc:creator><description>&lt;p&gt;Vice News has visited us at the German Film Museum and produced a short video about our &lt;a class="reference external" href="https://www.aesthetics.mpg.de/en/research/former-departments/department-of-neuroscience/aesthetic-experience/brain-on-screen.html"&gt;Cinema Project&lt;/a&gt;.
A very professional Crew - no nonsense shots and almost zero interference with the research workflow :)&lt;/p&gt;
&lt;p&gt;The short was &lt;a class="reference external" href="https://twitter.com/vicenews/status/1127211761654878208"&gt;published on their Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;img alt="Thumbnail from the video on twitter" class="align-center" src="http://dominikwelke.github.io/images/media/2019-vice-news.png" style="width: 60%;"&gt;</description><category>media</category><guid>http://dominikwelke.github.io/news/2019-05-vice-news-brain-on-screen/</guid><pubDate>Sat, 11 May 2019 15:21:34 GMT</pubDate></item></channel></rss>